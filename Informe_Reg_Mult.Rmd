---
title: "Informe Final"
author: "Fabricio Sánchez"
date: "2 de agosto de 2015"
output: html_document
---

### Introducción
En el presente informe se detallarán los pasos realizados en trabajo final de R.
### Descripción

### 2.1
Usando __readxl__ leemos las datas del proyecto y procedemos a analizar sus dimensiones.
Usando __datatable__ de la libreía __DT__ creamos un widget de las tablas para ser observadas. 

```{r,echo=TRUE,eval=TRUE}
options(warn=-1)
library(readxl)
library(DT)
data1 <- read_excel("poblacion1.xlsx",sheet=1,col_names = TRUE,na = "")
str(data1)
datatable(data1)
dim(data1)
data2 <- read_excel("poblacion2.xlsx",sheet=1,col_names = TRUE,na="")
str(data2)
datatable(data2)
dim(data2)
```

### 2.2
Usando la función __merge__ unimos las dos datas en una sola llamada __poblacion__
Luego la visualizamos y calculamos su dimensión

```{r,echo=TRUE,eval=TRUE}
options(warn=-1)
poblacion <- merge(data1,data2)
datatable(poblacion)
dim(poblacion)
```

### 2.3
Identificamos la clase de cada variable y realizamos diagramas de cajas para variables
contínuas y diagramas de barras para variables discretas
```{r,echo=T,eval=T}
options(warn=-1)
#Identificar la clase de cada variable
clase <- numeric(ncol(poblacion))
for (i in 1:ncol(poblacion)){
  clase[i] <- class(poblacion[,i])
}
clase
#Diagramas de cajas y barras
c <- function(i){
  boxplot(poblacion[,i])
}
for (i in 1:ncol(poblacion)){
  if (is.numeric(poblacion[,i])==T){
    c(i)
  }else{
    barplot(table(poblacion[,i]))
  }
}

```

### 2.4
Calculamos el mínimo, media, máximo, desviación estándar, primer cuartil de cada variable numérica y la frecuencia en el caso de variables categóricas.
```{r,echo=T,eval=T}
options(warn=-1)
mi <- numeric(8)
ma <- numeric(8)
med <- numeric(8)
dve <- numeric(8)
for (i in 1:ncol(poblacion)){
  if (is.numeric(poblacion[,i])==T){
    mi[i] <- min(poblacion[,i])
    ma[i] <- max(poblacion[,i])
    med[i] <- mean(poblacion[,i])
    dve[i] <- sd(poblacion[,i])
  }
}
mi
ma
med
dve

#cuartiles
quantile(poblacion[,1], probs = seq(0, 1, 0.25), na.rm = FALSE)
quantile(poblacion[,2], probs = seq(0, 1, 0.25), na.rm = FALSE)
quantile(poblacion[,3], probs = seq(0, 1, 0.25), na.rm = FALSE)
quantile(poblacion[,4], probs = seq(0, 1, 0.25), na.rm = FALSE)
quantile(poblacion[,5], probs = seq(0, 1, 0.25), na.rm = FALSE)
quantile(poblacion[,6], probs = seq(0, 1, 0.25), na.rm = FALSE)
quantile(poblacion[,7], probs = seq(0, 1, 0.25), na.rm = FALSE)
quantile(poblacion[,8], probs = seq(0, 1, 0.25), na.rm = FALSE)

#frecuencias
table(poblacion[,9])
table(poblacion[,10])

```

### 2.5
Hallamos la correlación entrela variable dependiente poblacion y cada una de las
variables explicativas (numéricas).
```{r,echo=T,eval=T}
options(warn=-1)
correl <-function(i){
  correl <- numeric(ncol(poblacion))
  
  for(i in 2:ncol(poblacion)){
    if(is.numeric(poblacion[,i])==TRUE){
      correl[i] <- cor(poblacion[,2], poblacion[,i])
    }
    
  }
  datos<-data.frame(names(poblacion),correl)
  datos
}
correl(poblacion)
```

### 2.6
Considerando la variable serv.bas.compl con una confiabilidad del 90%, ¿Pue-
de asumirse que la media de la variable poblacion en el grupo serv.bas.compl: SI
es distinta a la media del grupo serv.bas.compl: NO ?
Para responder esta pregunta calculamos y analizamos las varianzas para proceder
a una prueba de hipótesis
```{r,echo=T,eval=T}
options(warn=-1)
#para aplicar t.test necesitamos las varianzas
v1<-poblacion[,2]
v2<-poblacion[,10]
#analizamos las varianzas
var(v1[v2=="SI"])
var(v1[v2=="NO"])
#se evidencia que son distintas, realizamos nuestra prueba de hipotesis
t.test(v1[v2=="SI"], v1[v2=="NO"],conf.level = 0.90)
```
Como $t=`r t.test(v1[v2=="SI"], v1[v2=="NO"],conf.level = 0.90)[1]`$ es menor que $df=`r t.test(v1[v2=="SI"], v1[v2=="NO"],conf.level = 0.90)[2]`$ se acepta 
$H_0: u1-u2=0$.

### 2.7
Considerando los cálculos anteriores generamos el modelo que mejor se ajuste a nuestros 
datos
```{r,echo=T,eval=T}
options(warn=-1)
v2<-poblacion[,2]
v7<-poblacion[,7]
reg1<-lm(v1~v2+v7)
summary(reg1)
plot(reg1)
```
Analizando los gráficos podemos ver que el modelo es normal.

__Interpretación de Coeficientes__

Tenemos que: $B1=`r summary(reg1)[[4]][1,1]`$, $B2=`r summary(reg1)[[4]][1,2]`$ y $B3=`r summary(reg1)[[4]][1,3]`$ son significantes. También tenemos que, $Pr1=`r summary(reg1)[[4]][1,4]`$, $Pr2=`r summary(reg1)[[4]][2,4]`$ y $Pr3=`r summary(reg1)[[4]][3,4]`$ los cuales son valores muy pequeños con respecto a $t1=`r summary(reg1)[[4]][1,3]`$, $t2=`r summary(reg1)[[4]][2,3]`$ y $t3=`r summary(reg1)[[4]][3,3]`$ respectivamente  y por tanto podemos decir que nuestros coeficientes son significativos.

### 2.8
Procedemos a analizar el __R^2__

Como $R^2 = `r summary(reg1)[[8]]`$ podemos decir que aproximadamente el $`r (summary(reg1)[[8]])*100`$% de nuestra variación puede ser explicado por este modelo, además el $R^2 ajustado = `r summary(reg1)[[8]]`$ por lo tanto la regresión es significativa.

### 2.9
Debemos analizar la significancia de la regresión y de cada uno de los parámetros.
Para esto usaremos gráficos de dispersión, gráficos de normalidad e histogramas para
v1, v2 y v7.

__Gráficos de Dispersión__
__1__
```{r,echo=T,eval=T}
options(warn=-1)
library("ggplot2")
g <- ggplot(poblacion, aes(x=v1, y=v2))
g + geom_point() + geom_smooth(method="lm")
```
Se puede observar que hay relación lineal
__2__
```{r,echo=T,eval=T}
options(warn=-1)
g <- ggplot(poblacion, aes(x=v1, y=v7))
g + geom_point() + geom_smooth(method="lm")
```
Existe mayor dispersión
__3__
```{r,echo=T,eval=T}
options(warn=-1)
g <- ggplot(poblacion, aes(x=v2, y=v7))
g + geom_point() + geom_smooth(method="lm")
```
Existe mayor dispersión

__Gráficos de Normalidad__

__1__
```{r,echo=T,eval=T}
options(warn=-1)
qqnorm(v1)
qqline(v1,col="red")
```
Es notable que no se cumple el supuesto de normalidad
__2__
```{r,echo=T,eval=T}
options(warn=-1)
qqnorm(v2)
qqline(v2,col="red")
```
Es notable que no se cumple el supuesto de normalidad
__3__
```{r,echo=T,eval=T}
options(warn=-1)
qqnorm(v7)
qqline(v7,col="red")
```
Es notable la normalidad

__Histogramas__

__1__
```{r,echo=T,eval=T}
options(warn=-1)
hist(v1)
```

__2__
```{r,echo=T,eval=T}
options(warn=-1)
hist(v2)
```
Tendencia a normalidad y simetría
__3__
```{r,echo=T,eval=T}
options(warn=-1)
hist(v7)
```

### 2.10
Ahora procedemos a realizar un análisis detallado de los residuos

__Residuos__
```{r,echo=T,eval=T}
options(warn=-1)
res1<- reg1$residuals
```

Comparemos los residuos con v1, v2 y v7

```{r,echo=T,eval=T}
options(warn=-1)
g <- ggplot(poblacion, aes(x=v1, y=res1))
g + geom_point() + geom_smooth(method="lm")

g <- ggplot(poblacion, aes(x=v2, y=res1))
g + geom_point() + geom_smooth(method="lm")

g <- ggplot(poblacion, aes(x=v7, y=res1))
g + geom_point() + geom_smooth(method="lm")
```
Es observable que no tienen una distribución aleatoria en una banda con centro en cero
Procedemos a comparar los residuos con los pronósticos de nuestro modelo

__Pronóstios vs Residuos__
```{r,echo=T,eval=T}
options(warn=-1)
p1 <- reg1$fitted.values
plot(res1,p1)
```
Se observa que la linealidad se ve afectada debido a la disperción de los puntos y a la
existencia de puntos atípicos e influyentes.
Por lo notado anteriormente se concluye que requerimos de un ajuste de nuestro modelo
original.

__Reajuste__
```{r,echo=T,eval=T}
vaj1<-log(v1)
vaj2<-log(v2)
vaj7<-log(v7)
reg2<-lm(vaj1~vaj2+vaj7)
summary(reg2)
plot(reg2)
```
Ahora vemos que el modelo se ajusta mejor a la linealidad que el modelo original
ademas se puede aceptar el modelo de regresion multiple.